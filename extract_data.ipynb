{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('youtube': conda)",
   "metadata": {
    "interpreter": {
     "hash": "73e57928d5da8c743c0a2b72444a2a4ef8983e94bc1292f2d2a21105b12ce3a7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from names_dataset import NameDataset\n",
    "from pathlib import Path\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from difflib import SequenceMatcher\n",
    "from time import time\n",
    "import json\n",
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path.cwd().joinpath(\"DATA_FILES\")\n",
    "english_stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'challenge', 'feel', 'season', 'seasons', 'watcher', 'weird', 'yeah'}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "def filter_sentence(line: str, debug_print: bool = False) -> str:\n",
    "    if debug_print:\n",
    "        print(line.strip())\n",
    "    txt = re.sub(r\"(<([^>])*([^<])*([^>])*>)\", \"\", line) # delete everything contained in < > symbols\n",
    "    txt = re.sub(r\"([^a-zA-Z ])\", \" \", txt) # delete everything that is not letters\n",
    "    txt = re.sub(r'\\b\\w{1,1}\\b', '', txt) # delete everything that is one letter long\n",
    "    txt = re.sub(r'\\b\\w{70,}\\b', '', txt) # limiting words to 70 characters\n",
    "    txt = re.sub(r\"( +)\", \" \", txt) # delete all the extra spaces\n",
    "    list_of_text = txt.strip().lower().split(\" \") # delete whitespace at the end and beginning, lower and split on whitespace\n",
    "    set_of_text = set(list_of_text) # delete duplicates\n",
    "    set_of_text.difference_update(english_stop_words) # delete the most common words in English\n",
    "    if debug_print:\n",
    "        print(set_of_text)\n",
    "    return set_of_text\n",
    "\n",
    "    #return line.replace('.', ' ').replace('?', ' ').replace('\\'', ' ').replace('&quot', '\"')\n",
    "filter_sentence('Is it me or does it feel weird, being  A watcher of 100 baffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffby challenge but itâ€™s in season 32 seasons after this yeah this is weird <a href=\"http://www.youtube.com/results?search_query=%23gardensalad\">#GardenSalad</a>ðŸ¥—')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(data:dict, filepath: Path): \n",
    "    with filepath.open(mode='w') as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Duplicates:  28\n",
      "Finished with episode 1. Time: 0:4\n",
      "Duplicates:  17\n",
      "Finished with episode 2. Time: 0:4\n",
      "Duplicates:  25\n",
      "Finished with episode 3. Time: 0:4\n",
      "Duplicates:  56\n",
      "Finished with episode 4. Time: 0:8\n",
      "Duplicates:  31\n",
      "Finished with episode 5. Time: 0:5\n",
      "Duplicates:  102\n",
      "Finished with episode 6. Time: 0:5\n",
      "Duplicates:  66\n",
      "Finished with episode 7. Time: 0:8\n",
      "Duplicates:  60\n",
      "Finished with episode 8. Time: 0:8\n",
      "Duplicates:  217\n",
      "Finished with episode 9. Time: 1:6\n",
      "Duplicates:  172\n",
      "Finished with episode 10. Time: 0:22\n",
      "Duplicates:  78\n",
      "Finished with episode 11. Time: 0:9\n",
      "Duplicates:  183\n",
      "Finished with episode 12. Time: 0:18\n",
      "Duplicates:  157\n",
      "Finished with episode 13. Time: 0:21\n",
      "Duplicates:  89\n",
      "Finished with episode 14. Time: 0:12\n",
      "Duplicates:  85\n",
      "Finished with episode 15. Time: 0:18\n",
      "Duplicates:  97\n",
      "Finished with episode 16. Time: 0:14\n",
      "Duplicates:  59\n",
      "Finished with episode 17. Time: 0:8\n",
      "Duplicates:  60\n",
      "Finished with episode 18. Time: 0:6\n",
      "Duplicates:  35\n",
      "Finished with episode 19. Time: 0:5\n",
      "Duplicates:  36\n",
      "Finished with episode 20. Time: 0:5\n",
      "Duplicates:  118\n",
      "Finished with episode 21. Time: 0:11\n",
      "Duplicates:  120\n",
      "Finished with episode 22. Time: 0:11\n",
      "Duplicates:  76\n",
      "Finished with episode 23. Time: 0:9\n",
      "Duplicates:  89\n",
      "Finished with episode 24. Time: 0:7\n",
      "Duplicates:  46\n",
      "Finished with episode 25. Time: 0:6\n",
      "Duplicates:  25\n",
      "Finished with episode 26. Time: 0:3\n",
      "Duplicates:  19\n",
      "Finished with episode 27. Time: 0:2\n",
      "Duplicates:  27\n",
      "Finished with episode 28. Time: 0:4\n",
      "Duplicates:  31\n",
      "Finished with episode 29. Time: 0:5\n",
      "Duplicates:  36\n",
      "Finished with episode 30. Time: 0:8\n",
      "Duplicates:  14\n",
      "Finished with episode 31. Time: 0:5\n",
      "Duplicates:  25\n",
      "Finished with episode 32. Time: 0:4\n",
      "Duplicates:  28\n",
      "Finished with episode 33. Time: 0:3\n",
      "Duplicates:  15\n",
      "Finished with episode 34. Time: 0:5\n",
      "Duplicates:  39\n",
      "Finished with episode 35. Time: 0:5\n",
      "Duplicates:  119\n",
      "Finished with episode 36. Time: 0:5\n",
      "Duplicates:  46\n",
      "Finished with episode 37. Time: 0:5\n",
      "Duplicates:  34\n",
      "Finished with episode 38. Time: 0:7\n",
      "Duplicates:  42\n",
      "Finished with episode 39. Time: 0:7\n",
      "Duplicates:  37\n",
      "Finished with episode 40. Time: 0:5\n",
      "Duplicates:  21\n",
      "Finished with episode 41. Time: 0:2\n",
      "Duplicates:  15\n",
      "Finished with episode 42. Time: 0:3\n",
      "Duplicates:  14\n",
      "Finished with episode 43. Time: 0:2\n",
      "Duplicates:  22\n",
      "Finished with episode 44. Time: 0:3\n",
      "Duplicates:  46\n",
      "Finished with episode 45. Time: 0:2\n",
      "Duplicates:  25\n",
      "Finished with episode 46. Time: 0:3\n",
      "Duplicates:  18\n",
      "Finished with episode 47. Time: 0:3\n",
      "Duplicates:  37\n",
      "Finished with episode 48. Time: 0:3\n",
      "Duplicates:  29\n",
      "Finished with episode 49. Time: 0:3\n",
      "Duplicates:  26\n",
      "Finished with episode 50. Time: 0:3\n",
      "Duplicates:  19\n",
      "Finished with episode 51. Time: 0:3\n",
      "Duplicates:  14\n",
      "Finished with episode 52. Time: 0:4\n",
      "Duplicates:  16\n",
      "Finished with episode 53. Time: 0:2\n",
      "Duplicates:  22\n",
      "Finished with episode 54. Time: 0:2\n",
      "Duplicates:  15\n",
      "Finished with episode 55. Time: 0:2\n",
      "Duplicates:  15\n",
      "Finished with episode 56. Time: 0:2\n",
      "Duplicates:  5\n",
      "Finished with episode 57. Time: 0:2\n",
      "Duplicates:  58\n",
      "Finished with episode 58. Time: 0:2\n",
      "Duplicates:  31\n",
      "Finished with episode 59. Time: 0:1\n",
      "Duplicates:  10\n",
      "Finished with episode 60. Time: 0:1\n",
      "Duplicates:  31\n",
      "Finished with episode 61. Time: 0:3\n",
      "Duplicates:  19\n",
      "Finished with episode 62. Time: 0:2\n",
      "Duplicates:  34\n",
      "Finished with episode 63. Time: 0:2\n",
      "Duplicates:  17\n",
      "Finished with episode 64. Time: 0:2\n",
      "Duplicates:  27\n",
      "Finished with episode 65. Time: 0:1\n",
      "Duplicates:  7\n",
      "Finished with episode 66. Time: 0:1\n",
      "Duplicates:  10\n",
      "Finished with episode 67. Time: 0:2\n",
      "Duplicates:  18\n",
      "Finished with episode 68. Time: 0:1\n",
      "Duplicates:  20\n",
      "Finished with episode 69. Time: 0:2\n",
      "Duplicates:  20\n",
      "Finished with episode 70. Time: 0:2\n",
      "Duplicates:  43\n",
      "Finished with episode 71. Time: 0:1\n",
      "Duplicates:  29\n",
      "Finished with episode 72. Time: 0:2\n",
      "Duplicates:  14\n",
      "Finished with episode 73. Time: 0:1\n",
      "Duplicates:  42\n",
      "Finished with episode 74. Time: 0:1\n",
      "Duplicates:  8\n",
      "Finished with episode 75. Time: 0:1\n",
      "Duplicates:  35\n",
      "Finished with episode 76. Time: 0:1\n",
      "Duplicates:  79\n",
      "Finished with episode 77. Time: 0:2\n",
      "Duplicates:  46\n",
      "Finished with episode 78. Time: 0:1\n",
      "Duplicates:  80\n",
      "Finished with episode 79. Time: 0:1\n"
     ]
    }
   ],
   "source": [
    "def count_names(filtered_words: set, names_found:dict, name_dataset:NameDataset) -> dict:\n",
    "    for word in filtered_words:\n",
    "        try:\n",
    "            if name_dataset.search_first_name(word, use_upper_case=False):\n",
    "                if word in names_found:\n",
    "                    names_found[word] = names_found[word] + 1\n",
    "                else:\n",
    "                    names_found[word] = 1\n",
    "        except:\n",
    "            raise Exception(\"Error: \", word, \" in \",  filtered_words)\n",
    "    return names_found\n",
    "    \n",
    "def check_if_same_line(line: str, prev_line: str, count: int):\n",
    "    how_similar = similar(line, prev_line) > 0.9\n",
    "    # if(how_similar):\n",
    "    #     print(\"\\nLine {} and {} are {} similar: \\n{}{}\\n\".format(count-1, count, similar(line, prev_line), prev_line, line))\n",
    "    return how_similar\n",
    "\n",
    "\n",
    "def get_time(start_time):\n",
    "    m, s = divmod(time() - start_time, 60)\n",
    "    return m, s\n",
    "\n",
    "def for_every_comment_page(episode_data_path: Path, name_dataset:NameDataset):\n",
    "    page = 1\n",
    "    names_found = {}\n",
    "    data_path = episode_data_path.joinpath(f\"{str(page)}.txt\")\n",
    "    duplicates = 0\n",
    "    while(data_path.is_file()):\n",
    "        file1 = open(data_path, 'r', encoding='utf8', errors='ignore')\n",
    "        Lines = file1.readlines()\n",
    "        prev_line = \"\"\n",
    "        count = 0\n",
    "        for line in Lines:\n",
    "            count += 1\n",
    "            if check_if_same_line(line, prev_line, count):\n",
    "                duplicates += 1\n",
    "            else:\n",
    "                filtered_words = filter_sentence(line, False)\n",
    "                count_names(filtered_words, names_found, name_dataset)\n",
    "                prev_line = line\n",
    "\n",
    "        names_found = dict(sorted(names_found.items(), key=lambda item: item[1], reverse=True))\n",
    "        write_json(names_found, episode_data_path.joinpath(\"names_found.json\"))\n",
    "\n",
    "        page += 1\n",
    "        data_path = episode_data_path.joinpath(f\"{str(page)}.txt\")\n",
    "    print(\"Duplicates: \", duplicates)\n",
    "    return names_found\n",
    "\n",
    "name_dataset = NameDataset()\n",
    "for episode in range(1, 80):\n",
    "    start_time_video = time()\n",
    "    episode_data_path = data_path.joinpath(str(episode))\n",
    "    if(episode_data_path.exists()):\n",
    "        for_every_comment_page(episode_data_path, name_dataset)\n",
    "    else:\n",
    "        raise Exception(\"Directory not found\", episode_data_path) \n",
    "\n",
    "    m, s = get_time(start_time_video)\n",
    "    print(f\"Finished with episode {episode}. Time: {m:.0f}:{s:.000f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished with episode 1\n",
      "Finished with episode 2\n",
      "Finished with episode 3\n",
      "Finished with episode 4\n",
      "Finished with episode 5\n",
      "Finished with episode 6\n",
      "Finished with episode 7\n",
      "Finished with episode 8\n",
      "Finished with episode 9\n",
      "Finished with episode 10\n",
      "Finished with episode 11\n",
      "Finished with episode 12\n",
      "Finished with episode 13\n",
      "Finished with episode 14\n",
      "Finished with episode 15\n",
      "Finished with episode 16\n",
      "Finished with episode 17\n",
      "Finished with episode 18\n",
      "Finished with episode 19\n",
      "Finished with episode 20\n",
      "Finished with episode 21\n",
      "Finished with episode 22\n",
      "Finished with episode 23\n",
      "Finished with episode 24\n",
      "Finished with episode 25\n",
      "Finished with episode 26\n",
      "Finished with episode 27\n",
      "Finished with episode 28\n",
      "Finished with episode 29\n",
      "Finished with episode 30\n",
      "Finished with episode 31\n",
      "Finished with episode 32\n",
      "Finished with episode 33\n",
      "Finished with episode 34\n",
      "Finished with episode 35\n",
      "Finished with episode 36\n",
      "Finished with episode 37\n",
      "Finished with episode 38\n",
      "Finished with episode 39\n",
      "Finished with episode 40\n",
      "Finished with episode 41\n",
      "Finished with episode 42\n",
      "Finished with episode 43\n",
      "Finished with episode 44\n",
      "Finished with episode 45\n",
      "Finished with episode 46\n",
      "Finished with episode 47\n",
      "Finished with episode 48\n",
      "Finished with episode 49\n",
      "Finished with episode 50\n",
      "Finished with episode 51\n",
      "Finished with episode 52\n",
      "Finished with episode 53\n",
      "Finished with episode 54\n",
      "Finished with episode 55\n",
      "Finished with episode 56\n",
      "Finished with episode 57\n",
      "Finished with episode 58\n",
      "Finished with episode 59\n",
      "Finished with episode 60\n",
      "Finished with episode 61\n",
      "Finished with episode 62\n",
      "Finished with episode 63\n",
      "Finished with episode 64\n",
      "Finished with episode 65\n",
      "Finished with episode 66\n",
      "Finished with episode 67\n",
      "Finished with episode 68\n",
      "Finished with episode 69\n",
      "Finished with episode 70\n",
      "Finished with episode 71\n",
      "Finished with episode 72\n",
      "Finished with episode 73\n",
      "Finished with episode 74\n",
      "Finished with episode 75\n",
      "Finished with episode 76\n",
      "Finished with episode 77\n",
      "Finished with episode 78\n",
      "Finished with episode 79\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "total_results = {}\n",
    "for episode in range(1, 80):\n",
    "    episode_data_path = data_path.joinpath(str(episode), \"names_found.json\")\n",
    "    if(episode_data_path.exists()):\n",
    "        # Get data and add it to total_results\n",
    "        with open(episode_data_path) as json_file: \n",
    "            data = json.load(json_file)\n",
    "            total_results[episode] = data\n",
    "    else:\n",
    "        raise Exception(\"Directory not found\", episode_data_path) \n",
    "\n",
    "    print(f\"Finished with episode {episode}\")\n",
    "write_json(total_results, data_path.joinpath(\"total_results.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from names_dataset import NameDataset\n",
    "from pathlib import Path\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from difflib import SequenceMatcher\n",
    "from time import time\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Line1: <!--Olive-->\nOlive\nLine2: {{.child|n=1|col4={{lesbian}}|age={{elder}}|col6={{sim}}|col7=|col9=[[Marcus Flex]]|col10={{old.age}}}}\n[('[[Marcus Flex]]', 'Marcus Flex')]\nMarcus Flex\nLine3: <!--Brielle-->\nBrielle\nLine4: {{.child|n=2|col4={{female}}|age={{elder}}|col6={{sim}}|col7=|col9=[[Dominic Fyres]]|col10={{old.age}}}}\n[('[[Dominic Fyres]]', 'Dominic Fyres')]\nDominic Fyres\nLine5: <!--Jaime-->\nJaime\nLine6: {{.child|n=3|col4={{male}}|age={{elder}}|col6={{sim}}|col7=|col9=[[J Huntington III]]|col10={{old.age}}}}\n[('[[J Huntington III]]', 'J Huntington III')]\nJ Huntington III\nLine7: <!--Alexis-->\nAlexis\nLine8: {{.child|n=4|col4={{female}}|age={{elder}}|col6={{sim}}|col7=|col9=[[Sergio Romeo]]|col10={{old.age}}}}\n[('[[Sergio Romeo]]', 'Sergio Romeo')]\nSergio Romeo\nLine9: <!--Miles-->\nMiles\nLine10: {{.child|n=5|col4={{male}}|age={{elder}}|col6={{sim}}|col7={{twin|#=1}}|col9=[[Lars Rosewood]]|rs=2|col10={{old.age}}}}\n[('[[Lars Rosewood]]', 'Lars Rosewood')]\nLars Rosewood\nLine11: <!--Renee-->\nRenee\nLine12: {{.child.x|n=6|col4={{female}}|age={{elder}}|col6={{sim}}|col10={{old.age}}}}\n[]\nLars Rosewood\nLine13: <!--Charlie-->\nCharlie\nLine14: {{.child|n=7|col4={{male}}|age={{elder}}|col6={{sim}}|col7=|col9=[[Craig Slater]]|col10={{old.age}}}}\n[('[[Craig Slater]]', 'Craig Slater')]\nCraig Slater\nLine15: <!--Hazel-->\nHazel\nLine16: {{.child|n=8|col4={{female}}|age={{elder}}|col6={{sim}}|col7=|col9=[[Kim Mingyu]]|col10={{old.age}}}}\n[('[[Kim Mingyu]]', 'Kim Mingyu')]\nKim Mingyu\nLine17: <!--Eric-->\nEric\nLine18: {{.child|n=9|col4={{male}}|age={{elder}}|col6={{sim}}|col7=|col9=[[Caron Simmons]]|col10={{old.age}}}}\n[('[[Caron Simmons]]', 'Caron Simmons')]\nCaron Simmons\nLine19: <!--Niya-->\nNiya\nLine20: {{.child|n=10|col4={{bi|female}}|age={{YA}}|col6={{vampire}}|col7={{twin|#=2}}|col9=[[Steven Smith]]|rs=2|col10={{immortal}}}}\n[('[[Steven Smith]]', 'Steven Smith')]\nSteven Smith\nLine21: <!--Natalie-->\nNatalie\nLine22: {{.child.x|n=11|col4={{female}}|age={{YA}}|col6={{vampire}}|col10={{immortal}}}}\n[]\nSteven Smith\nLine23: <!--RosÃƒÂ©-->\nRos\nLine24: {{.child|n=12|col4={{female}}|age={{elder}}|col6={{sim}}|col7={{twin|#=3}}|col9=[[Maria Wills]]|rs=2|col10={{old.age}}}}\n[('[[Maria Wills]]', 'Maria Wills')]\nMaria Wills\nLine25: <!--River-->\nRiver\nLine26: {{.child.x|n=13|col4={{male}}|age={{elder}}|col6={{sim}}|col10={{old.age}}}}\n[]\nMaria Wills\nLine27: <!--Flynn-->\nFlynn\nLine28: {{.child|n=14|col4={{male}}|age={{elder}}|col6={{sim}}|col7={{twin|#=4}}|col9=[[Cayden Cross]]|rs=2|col10={{old.age}}}}\n[('[[Cayden Cross]]', 'Cayden Cross')]\nCayden Cross\nLine29: <!--Cooper-->\nCooper\nLine30: {{.child.x|n=15|col4={{male}}|age={{elder}}|col6={{sim}}|col10={{old.age}}}}\n[]\nCayden Cross\nLine31: <!--Addi-->\nAddi\nLine32: {{.child|n=16|col4={{female}}|age={{elder}}|col6={{sim}}|col7=|col9=[[Yusuf Malik]]|col10={{old.age}}}}\n[('[[Yusuf Malik]]', 'Yusuf Malik')]\nYusuf Malik\nLine33: <!--Ellie-->\nEllie\nLine34: {{.child|n=17|col4={{female}}|age={{elder}}|col6={{sim}}|col7={{twin|#=5}}|col9=[[Craig Dream Daddy]]|rs=2|col10={{old.age}}}}\n[('[[Craig Dream Daddy]]', 'Craig Dream Daddy')]\nCraig Dream Daddy\nLine35: <!--Dorian-->\nDorian\nLine36: {{.child.x|n=18|col4={{male}}|age={{elder}}|col6={{sim}}|col10={{old.age}}}}\n[]\nCraig Dream Daddy\nLine37: <!--Theo-->\nTheo\nLine38: {{.child|n=19|col4={{male}}|age={{elder}}|col6={{sim}}|col7={{twin|#=6}}|col9=[[Hailey Willis]]|rs=2|col10={{old.age}}}}\n[('[[Hailey Willis]]', 'Hailey Willis')]\nHailey Willis\nLine39: <!--Tristen-->\nTristen\nLine40: {{.child.x|n=20|col4={{male}}|age={{elder}}|col6={{sim}}|col10={{old.age}}}}\n[]\nHailey Willis\nLine41: <!--Willow-->\nWillow\nLine42: {{.child|n=21|col4={{female}}|age={{elder}}|col6={{sim}}|col7={{twin|#=7}}|col9=[[Hamza Mounib]]|rs=2|col10={{old.age}}}}\n[('[[Hamza Mounib]]', 'Hamza Mounib')]\nHamza Mounib\nLine43: <!--Ginny-->\nGinny\nLine44: {{.child.x|n=22|col4={{enby}}|age={{elder}}|col6={{sim}}|col10={{old.age}}}}\n[]\nHamza Mounib\nLine45: <!--Bran-->\nBran\nLine46: {{.child|n=23|col4={{male}}|age={{elder}}|col6={{alien-sim}}|col7=|col9=[[Kade Pelletier]]|col10={{old.age}}}}\n[('[[Kade Pelletier]]', 'Kade Pelletier')]\nKade Pelletier\nLine47: <!--Jon-->\nJon\nLine48: {{.child|n=24|col4={{male}}|age={{elder}}|col6={{sim}}|col7={{twin|#=8}}|col9=[[Korbin Sherwood]]|rs=2|col10={{old.age}}}}\n[('[[Korbin Sherwood]]', 'Korbin Sherwood')]\nKorbin Sherwood\nLine49: <!--Arya-->\nArya\nLine50: {{.child.x|n=25|col4={{female}}|age={{elder}}|col6={{sim}}|col10={{old.age}}}}\n[]\nKorbin Sherwood\nLine51: <!--Nova-->\nNova\nLine52: {{.child|n=26|col4={{female}}|age={{elder}}|col6={{sim}}|col7={{twin|#=9}}|col9=[[Chance Turner]]|rs=2|col10={{old.age}}}}\n[('[[Chance Turner]]', 'Chance Turner')]\nChance Turner\nLine53: <!--Freya-->\nFreya\nLine54: {{.child.x|n=27|col4={{female}}|age={{elder}}|col6={{sim}}|col10={{old.age}}}}\n[]\nChance Turner\nLine55: <!--Sirius-->\nSirius\nLine56: {{.child|n=28|col4={{male}}|age={{elder}}|col6={{sim}}|col7={{twin|#=10}}|col9=[[Jordan Weir]]|rs=2|col10={{old.age}}}}\n[('[[Jordan Weir]]', 'Jordan Weir')]\nJordan Weir\nLine57: <!--Stacey-->\nStacey\nLine58: {{.child.x|n=29|col4={{female}}|age={{elder}}|col6={{sim}}|col10={{old.age}}}}\n[]\nJordan Weir\nLine59: <!--Kasey-->\nKasey\nLine60: {{.child|n=30|col4={{bi|female}}|age={{elder}}|col6={{sim}}|col7=|col9=[[Jace Thomas]]|col10=}}\n[('[[Jace Thomas]]', 'Jace Thomas')]\nJace Thomas\nLine61: <!--Taylor-->\nTaylor\nLine62: {{.child|n=31|col4={{male}}|age={{elder}}|col6={{sim}}|col7={{twin|#=11}}|col9=[[Khaled Al Fassi]]|rs=2|col10={{old.age}}}}\n[('[[Khaled Al Fassi]]', 'Khaled Al Fassi')]\nKhaled Al Fassi\nLine63: <!--Tayler-->\nTayler\nLine64: {{.child.x|n=32|col4={{male}}|age={{elder}}|col6={{sim}}|col10={{old.age}}}}\n[]\nKhaled Al Fassi\nLine65: <!--Tegan-->\nTegan\nLine66: {{.child|n=33|col4={{male}}|age={{elder}}|col6={{sim}}|col7={{twin|#=12}}|col9=[[Hawea Paoa]]|rs=2|col10={{old.age}}}}\n[('[[Hawea Paoa]]', 'Hawea Paoa')]\nHawea Paoa\nLine67: <!--Archer-->\nArcher\nLine68: {{.child.x|n=34|col4={{male}}|age={{elder}}|col6={{sim}}|col10={{old.age}}}}\n[]\nHawea Paoa\nLine69: <!--Blaire-->\nBlaire\nLine70: {{.child|n=35|col4={{female}}|age={{elder}}|col6={{sim}}|col7={{triplets}}|col9=[[Afu Savea]]|rs=3|col10={{old.age}}}}\n[('[[Afu Savea]]', 'Afu Savea')]\nAfu Savea\nLine71: <!--Brooke-->\nBrooke\nLine72: {{.child.x|n=36|col4={{female}}|age={{elder}}|col6={{sim}}|col10={{old.age}}}}\n[]\nAfu Savea\nLine73: <!--Brendon-->\nBrendon\nLine74: {{.child.x|n=37|col4={{male}}|age={{elder}}|col6={{sim}}|col10={{old.age}}}}\n[]\nAfu Savea\nLine75: <!--Hope-->\nHope\nLine76: {{.child|n=38|col4={{female}}|age={{elder}}|col6={{sim}}|col7={{twin|#=13}}|col9=[[Seiji Tanaka]]|rs=2|col10={{old.age}}}}\n[('[[Seiji Tanaka]]', 'Seiji Tanaka')]\nSeiji Tanaka\nLine77: <!--Bella-->\nBella\nLine78: {{.child.x|n=39|col4={{female}}|age={{elder}}|col6={{sim}}|col9=|col10={{old.age}}}}\n[]\nSeiji Tanaka\nLine79: <!--Ever-->\nEver\nLine80: {{.child|n=40|col4={{female}}|age={{elder}}|col6={{sim}}|col7={{twin|#=14}}|col9=[[Derumk Kealoha]]|rs=2}}\n[('[[Derumk Kealoha]]', 'Derumk Kealoha')]\nDerumk Kealoha\nLine81: <!--Jake-->\nJake\nLine82: {{.child.x|n=41|col4={{male}}|age={{elder}}|col6={{sim}}}}\n[]\nDerumk Kealoha\nLine83: <!--Romeo-->\nRomeo\nLine84: {{.child|n=42|col4={{male}}|age={{elder}}|col6={{sim}}|col7={{twin|#=15}}|col9=[[Sai Ramesh]]|rs=2}}\n[('[[Sai Ramesh]]', 'Sai Ramesh')]\nSai Ramesh\nLine85: <!--Caesar-->\nCaesar\nLine86: {{.child.x|n=43|col4={{male}}|age={{elder}}|col6={{sim}}|col9=}}\n[]\nSai Ramesh\nLine87: <!--Harry-->\nHarry\nLine88: {{.child|n=h|col4={{male}}|age={{teen}}|col6={{sim}}|col7={{twin|#=16}}|col9=[[Duane Talla]]|rs=2|col10={{drowning}}}}\n[('[[Duane Talla]]', 'Duane Talla')]\nDuane Talla\nLine89: <!--Dustin-->\nDustin\nLine90: {{.child.x|n=44|col4={{male}}|age={{adult}}|col6={{sim}}}}\n[]\nDuane Talla\nLine91: <!--Leo, Jr.-->\nLeoJr\nLine92: {{.child|n=45|col4={{male}}|age={{adult}}|col6={{sim}}|col7=|col9=[[Leonardo DiCaprio]]}}\n[('[[Leonardo DiCaprio]]', 'Leonardo DiCaprio')]\nLeonardo DiCaprio\nLine93: <!--Logan-->\nLogan\nLine94: {{.child|n=46|col4={{male}}|age={{adult}}|col6={{sim}}|col7=|col9=[[Serena Moore]]}}\n[('[[Serena Moore]]', 'Serena Moore')]\nSerena Moore\nLine95: <!--Holly-->\nHolly\nLine96: {{.child|n=47|col4={{female}}|age={{adult}}|col6={{sim}}|col7={{twin|#=17}}|col9=[[James Potter]]|rs=2}}\n[('[[James Potter]]', 'James Potter')]\nJames Potter\nLine97: <!--Hayley-->\nHayley\nLine98: {{.child.x|n=48|col4={{female}}|age={{adult}}|col6={{sim}}}}\n[]\nJames Potter\nLine99: <!--Olivia-->\nOlivia\nLine100: {{.child|n=49|col4={{female}}|age={{YA}}|col6={{sim}}|col7=|col9=[[Tom Holland]]}}\n[('[[Tom Holland]]', 'Tom Holland')]\nTom Holland\nLine101: <!--Chelsea, Jr.-->\nChelseaJr\nLine102: {{.child|n=50|col4={{pan|female}}|age={{YA}}|col6={{sim}}|col7=|col9=[[Finnegan Lambert]]}}\n[('[[Finnegan Lambert]]', 'Finnegan Lambert')]\nFinnegan Lambert\nLine103: <!--Annie-->\nAnnie\nLine104: {{.child|n=51|col4={{female}}|age={{YA}}|col6={{sim}}|col7={{twin|#=18}}|col9=[[Theo Beckett]]|rs=2}}\n[('[[Theo Beckett]]', 'Theo Beckett')]\nTheo Beckett\nLine105: <!--Ashton-->\nAshton\nLine106: {{.child.x|n=52|col4={{male}}|age={{YA}}|col6={{sim}}}}\n[]\nTheo Beckett\nLine107: <!--Phoebe-->\nPhoebe\nLine108: {{.child|n=53|col4={{female}}|age={{YA}}|col6={{sim}}|col7=|col9=[[Remus Lupin]]}}\n[('[[Remus Lupin]]', 'Remus Lupin')]\nRemus Lupin\nLine109: <!--Owen-->\nOwen\nLine110: {{.child|n=54|col4={{male}}|age={{YA}}|col6={{sim}}|col7={{twin|#=19}}|col9=[[Leonardo Parish]]|rs=2}}\n[('[[Leonardo Parish]]', 'Leonardo Parish')]\nLeonardo Parish\nLine111: <!--Lucien-->\nLucien\nLine112: {{.child.x|n=55|col4={{male}}|age={{YA}}|col6={{sim}}}}\n[]\nLeonardo Parish\nLine113: <!--Autumn-->\nAutumn\nLine114: {{.child|n=56|col4={{female}}|age={{YA}}|col6={{sim}}|col7={{twin|#=20}}|col9=[[Noel Fritz]]|rs=2}}\n[('[[Noel Fritz]]', 'Noel Fritz')]\nNoel Fritz\nLine115: <!--August-->\nAugust\nLine116: {{.child.x|n=57|col4={{male}}|age={{YA}}|col6={{sim}}}}\n[]\nNoel Fritz\nLine117: <!--Mars-->\nMars\nLine118: {{.child|n=58|col4={{male}}|age={{YA}}|col6={{sim}}|col7={{twin|#=21}}|col9=[[Brooke Pieterson]]|rs=2}}\n[('[[Brooke Pieterson]]', 'Brooke Pieterson')]\nBrooke Pieterson\nLine119: <!--Conner-->\nConner\nLine120: {{.child.x|n=59|col4={{male}}|age={{YA}}|col6={{sim}}}}\n[]\nBrooke Pieterson\nLine121: <!--Blake-->\nBlake\nLine122: {{.child|n=60|col4={{female}}|age={{YA}}|col6={{spellcaster}}|col7=|col9=[[Darrel Charm]]}}\n[('[[Darrel Charm]]', 'Darrel Charm')]\nDarrel Charm\nLine123: <!--Hannah-->\nHannah\nLine124: {{.child|n=61|col4={{female}}|age={{YA}}|col6={{sim}}|col7={{twin|#=22}}|col9=[[Fetu Paewai]]|rs=2|col10=}}\n[('[[Fetu Paewai]]', 'Fetu Paewai')]\nFetu Paewai\nLine125: <!--Elliot-->\nElliot\nLine126: {{.child.x|n=62|col4={{female}}|age={{YA}}|col6={{sim}}|col10=}}\n[]\nFetu Paewai\nLine127: <!--Oliver-->\nOliver\nLine128: {{.child|n=63|col4={{male}}|age={{YA}}|col6={{sim}}|col7=|col9=[[Stephen Andersen]]|col10=}}\n[('[[Stephen Andersen]]', 'Stephen Andersen')]\nStephen Andersen\nLine129: <!--Kelly-->\nKelly\nLine130: {{.child|n=64|col4={{bi|female}}|age={{YA}}|col6={{sim}}|col7={{twin|#=23}}|col9=[[Ryder Milligan]]|rs=2|col10={{home}}}}\n[('[[Ryder Milligan]]', 'Ryder Milligan')]\nRyder Milligan\nLine131: <!--Wesley-->\nWesley\nLine132: {{.child.x|n=65|col4={{male}}|age={{YA}}|col6={{sim}}|col10={{emb}}}}\n[]\nRyder Milligan\nLine133: <!--Henry-->\nHenry\nLine134: {{.child|n=66|col4={{male}}|age={{YA}}|col6={{sim}}|col7={{twin|#=24}}|col9=[[Adam Beast]]|rs=2|col10=}}\n[('[[Adam Beast]]', 'Adam Beast')]\nAdam Beast\nLine135: <!--Holden-->\nHolden\nLine136: {{.child.x|n=67|col4={{gay}}|age={{YA}}|col6={{sim}}|col10=}}\n[]\nAdam Beast\nLine137: <!--Josie-->\nJosie\nLine138: {{.child|n=68|col4={{female}}|age={{YA}}|col6={{sim}}|col7={{twin|#=25}}|col9=[[Jase Marroquin]]|rs=2|col10=}}\n[('[[Jase Marroquin]]', 'Jase Marroquin')]\nJase Marroquin\nLine139: <!--Cove-->\nCove\nLine140: {{.child.x|n=69|col4={{female}}|age={{YA}}|col6={{sim}}|col10=}}\n[]\nJase Marroquin\nLine141: <!--Delilah-->\nDelilah\nLine142: {{.child|n=70|col4={{ace|female}}|age={{YA}}|col6={{sim}}|col7={{twin|#=26}}|col9=[[Fred Jenson]]|rs=2|col10=}}\n[('[[Fred Jenson]]', 'Fred Jenson')]\nFred Jenson\nLine143: <!--Danyel-->\nDanyel\nLine144: {{.child.x|n=71|col4={{female}}|age={{YA}}|col6={{sim}}|col10=}}\n[]\nFred Jenson\nLine145: <!--Ruth-->\nRuth\nLine146: {{.child|n=72|col4={{trans|female}}|age={{YA}}|col6={{sim}}|col9=[[Messiah Reed]]|col10=}}\n[('[[Messiah Reed]]', 'Messiah Reed')]\nMessiah Reed\nLine147: <!--Todd-->\nTodd\nLine148: {{.child|n=73|col4={{male}}|age={{YA}}|col6={{sim}}|col7={{twin|#=27}}|col9=[[Carlos Dias]]|col10=|rs=2}}\n[('[[Carlos Dias]]', 'Carlos Dias')]\nCarlos Dias\nLine149: <!--Jacob-->\nJacob\nLine150: {{.child.x|n=74|col4={{male}}|age={{YA}}|col6={{sim}}|col10=}}\n[]\nCarlos Dias\nLine151: <!--Eileen-->\nEileen\nLine152: {{.child|n=75|col4={{female}}|age={{YA}}|col6={{sim}}|col7={{twin|#=28}}|col9=[[Aquaman Momoa]]|col10=|rs=2}}\n[('[[Aquaman Momoa]]', 'Aquaman Momoa')]\nAquaman Momoa\nLine153: <!--Waldo-->\nWaldo\nLine154: {{.child.x|n=76|col4={{male}}|age={{YA}}|col6={{sim}}|col10=}}\n[]\nAquaman Momoa\nLine155: <!--Jennie-->\nJennie\nLine156: {{.child|n=77|col4={{female}}|age={{YA}}|col6={{sim}}|col7=|col9=[[BTS Namjoon]]|col10=|rs=1}}\n[('[[BTS Namjoon]]', 'BTS Namjoon')]\nBTS Namjoon\nLine157: <!--Rebekah-->\nRebekah\nLine158: {{.child|n=78|col4={{female}}|age={{YA}}|col6={{sim}}|col7={{twin|#=29}}|col9=[[BTS Jungkook]]|col10=|rs=2}}\n[('[[BTS Jungkook]]', 'BTS Jungkook')]\nBTS Jungkook\nLine159: <!--Dwayne-->\nDwayne\nLine160: {{.child.x|n=79|col4={{male}}|age={{YA}}|col6={{sim}}|col7=|col10=}}\n[]\nBTS Jungkook\nLine161: <!--Loki-->\nLoki\nLine162: {{.child|n=80|col4={{male}}|age={{YA}}|col6={{sim}}|col7={{twin|#=30}}|col9=[[Monica Geller]]|col10=|rs=2}}\n[('[[Monica Geller]]', 'Monica Geller')]\nMonica Geller\nLine163: <!--Eleanor-->\nEleanor\nLine164: {{.child.x|n=81|col4={{female}}|age={{YA}}|col6={{sim}}|col7=|col10=}}\n[]\nMonica Geller\nLine165: <!--Koya-->\nKoya\nLine166: {{.child|n=82|col4={{male}}|age={{YA}}|col6={{sim}}|col7={{twin|#=31}}|col9=[[BTS Jimin]]|col10=|rs=2}}\n[('[[BTS Jimin]]', 'BTS Jimin')]\nBTS Jimin\nLine167: <!--Rain-->\nRain\nLine168: {{.child.x|n=83|col4={{male}}|age={{YA}}|col6={{sim}}|col7=|col10=}}\n[]\nBTS Jimin\nLine169: <!--Baby-->\nBaby\nLine170: {{.child|n=84|col4={{female}}|age={{YA}}|col6={{sim}}|col7={{twin|#=32}}|col9=[[BTS J-Hope]]|col10=|rs=2}}\n[('[[BTS J-Hope]]', 'BTS J-Hope')]\nBTS J-Hope\nLine171: <!--Jane-->\nJane\nLine172: {{.child.x|n=85|col4={{lesbian}}|age={{YA}}|col6={{sim}}|col7=|col10=}}\n[]\nBTS J-Hope\nLine173: <!--Han-->\nHan\nLine174: {{.child|n=86|col4={{male}}|age={{YA}}|col6={{sim}}|col7={{twin|#=33}}|col9=[[BTS Taehyung]]|col10=|rs=2}}\n[('[[BTS Taehyung]]', 'BTS Taehyung')]\nBTS Taehyung\nLine175: <!--Hwan-->\nHwan\nLine176: {{.child.x|n=87|col4={{male}}|age={{YA}}|col6={{sim}}|col7=|col10={{home}}}}\n[]\nBTS Taehyung\nLine177: <!--Keira-->\nKeira\nLine178: {{.child|n=88|col4={{female}}|age={{YA}}|col6={{sim}}|col7=|col9=[[Ekam Khosa]]|col10={{home}}}}\n[('[[Ekam Khosa]]', 'Ekam Khosa')]\nEkam Khosa\nLine179: <!--Teddy-->\nTeddy\nLine180: {{.child|n=89|col4={{male}}|age={{toddler}}|col6={{sim}}|col7=|col9=[[Cataleya Collins]]|col10={{home}}}}\n[('[[Cataleya Collins]]', 'Cataleya Collins')]\nCataleya Collins\nLine181: <!--Levi-->\nLevi\nLine182: {{.child|n=90|col4={{male}}|age={{baby}}|col6={{sim}}|col7={{twin|#=34}}|col9=[[Maleficent Moors]]|col10={{home}}|rs=2}}\n[('[[Maleficent Moors]]', 'Maleficent Moors')]\nMaleficent Moors\nLine183: <!--Belle-->\nBelle\nLine184: {{.child.x3|n=91|col4={{female}}|age={{baby}}|col6={{sim}}|col10={{home.x}}}}\n[]\nMaleficent Moors\nLine185: |}</div>\ndiv\n[['Olive', 'Marcus Flex'], ['Brielle', 'Dominic Fyres'], ['Jaime', 'J Huntington III'], ['Alexis', 'Sergio Romeo'], ['Miles', 'Lars Rosewood'], ['Renee', 'Lars Rosewood'], ['Charlie', 'Craig Slater'], ['Hazel', 'Kim Mingyu'], ['Eric', 'Caron Simmons'], ['Niya', 'Steven Smith'], ['Natalie', 'Steven Smith'], ['RosÃ©', 'Maria Wills'], ['River', 'Maria Wills'], ['Flynn', 'Cayden Cross'], ['Cooper', 'Cayden Cross'], ['Addi', 'Yusuf Malik'], ['Ellie', 'Craig Dream Daddy'], ['Dorian', 'Craig Dream Daddy'], ['Theo', 'Hailey Willis'], ['Tristen', 'Hailey Willis'], ['Willow', 'Hamza Mounib'], ['Ginny', 'Hamza Mounib'], ['Bran', 'Kade Pelletier'], ['Jon', 'Korbin Sherwood'], ['Arya', 'Korbin Sherwood'], ['Nova', 'Chance Turner'], ['Freya', 'Chance Turner'], ['Sirius', 'Jordan Weir'], ['Stacey', 'Jordan Weir'], ['Kasey', 'Jace Thomas'], ['Taylor', 'Khaled Al Fassi'], ['Tayler', 'Khaled Al Fassi'], ['Tegan', 'Hawea Paoa'], ['Archer', 'Hawea Paoa'], ['Blaire', 'Afu Savea'], ['Brooke', 'Afu Savea'], ['Brendon', 'Afu Savea'], ['Hope', 'Seiji Tanaka'], ['Bella', 'Seiji Tanaka'], ['Ever', 'Derumk Kealoha'], ['Jake', 'Derumk Kealoha'], ['Romeo', 'Sai Ramesh'], ['Caesar', 'Sai Ramesh'], ['Harry', 'Duane Talla'], ['Dustin', 'Duane Talla'], ['LeoJr', 'Leonardo DiCaprio'], ['Logan', 'Serena Moore'], ['Holly', 'James Potter'], ['Hayley', 'James Potter'], ['Olivia', 'Tom Holland'], ['ChelseaJr', 'Finnegan Lambert'], ['Annie', 'Theo Beckett'], ['Ashton', 'Theo Beckett'], ['Phoebe', 'Remus Lupin'], ['Owen', 'Leonardo Parish'], ['Lucien', 'Leonardo Parish'], ['Autumn', 'Noel Fritz'], ['August', 'Noel Fritz'], ['Mars', 'Brooke Pieterson'], ['Conner', 'Brooke Pieterson'], ['Blake', 'Darrel Charm'], ['Hannah', 'Fetu Paewai'], ['Elliot', 'Fetu Paewai'], ['Oliver', 'Stephen Andersen'], ['Kelly', 'Ryder Milligan'], ['Wesley', 'Ryder Milligan'], ['Henry', 'Adam Beast'], ['Holden', 'Adam Beast'], ['Josie', 'Jase Marroquin'], ['Cove', 'Jase Marroquin'], ['Delilah', 'Fred Jenson'], ['Danyel', 'Fred Jenson'], ['Ruth', 'Messiah Reed'], ['Todd', 'Carlos Dias'], ['Jacob', 'Carlos Dias'], ['Eileen', 'Aquaman Momoa'], ['Waldo', 'Aquaman Momoa'], ['Jennie', 'BTS Namjoon'], ['Rebekah', 'BTS Jungkook'], ['Dwayne', 'BTS Jungkook'], ['Loki', 'Monica Geller'], ['Eleanor', 'Monica Geller'], ['Koya', 'BTS Jimin'], ['Rain', 'BTS Jimin'], ['Baby', 'BTS J-Hope'], ['Jane', 'BTS J-Hope'], ['Han', 'BTS Taehyung'], ['Hwan', 'BTS Taehyung'], ['Keira', 'Ekam Khosa'], ['Teddy', 'Cataleya Collins'], ['Levi', 'Maleficent Moors'], ['Belle', 'Maleficent Moors']]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "file1 = open(Path.cwd().joinpath(\"children.txt\"), 'r')\n",
    "Lines = file1.readlines()\n",
    " \n",
    "count = 1\n",
    "# Strips the newline character\n",
    "\n",
    "def filter_sentence(line: str, debug_print: bool = False) -> str:\n",
    "    if debug_print:\n",
    "        print(line.strip())\n",
    "    txt = re.sub(r\"([^a-zA-Z ])\", \"\", line)\n",
    "total = []\n",
    "pair = []\n",
    "prev_parent = \"\"\n",
    "for line in Lines:\n",
    "    txt = \"\"\n",
    "    print(\"Line{}: {}\".format(count, line.strip()))\n",
    "    if count % 2 == 1:\n",
    "        pair = []\n",
    "        txt = re.sub(r\"([^a-zA-Z])\", \"\", line)\n",
    "        pair.append(txt)\n",
    "    else:\n",
    "        txt = re.findall(r\"(\\[\\[([^\\]]*)\\]\\])\", line)\n",
    "        print(txt)\n",
    "        if(len(txt) == 0):\n",
    "            txt = prev_parent\n",
    "        else:\n",
    "            txt = txt[0][1]\n",
    "        prev_parent = txt\n",
    "        pair.append(txt)\n",
    "        total.append(pair)\n",
    "    count += 1\n",
    "    print(txt)\n",
    "total[11][0] = \"RosÃ©\"\n",
    "print(total)\n",
    "\n",
    "# Now use https://pypi.org/project/requests/ library to get the web-site \n",
    "r = requests.get('https://100-baby-challenge.fandom.com/wiki/Brooke_Impiccishmay')\n",
    "#r.content.decode('unicode_escape')\n",
    "txt = r.text\n",
    "len(txt)\n",
    "\n",
    "def get_birth_episode(name:str) -> int:\n",
    "    if(\"jr\" in name.lower()):\n",
    "        name_true = name.replace(\"Jr\", \"\")\n",
    "        link =  f\"https://100-baby-challenge.fandom.com/wiki/{name_true}_Impiccishmay,_Jr.\"\n",
    "    else:\n",
    "        link = f'https://100-baby-challenge.fandom.com/wiki/{name}_Impiccishmay'\n",
    "    r = requests.get(link)\n",
    "    txt = r.text\n",
    "    short_txt = txt[txt.find(\"age stages through the series\"):]\n",
    "    shorter_txt = short_txt[:short_txt.find(\"background:#f2f2f2; border-radius: 0 0 7px 0;\")]\n",
    "    part = shorter_txt[shorter_txt.find('>Part'):shorter_txt.find('</a>')]\n",
    "    if(len(part) == 0):\n",
    "        print(link)\n",
    "        print(len(txt), len(short_txt), len(shorter_txt), len(part))\n",
    "        print(shorter_txt)\n",
    "        print(part)\n",
    "    return int(re.findall(r\"\\d+\", part)[0])\n",
    "get_birth_episode(\"Brooke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Olive 1\n",
      "Brielle 2\n",
      "Jaime 2\n",
      "Alexis 4\n",
      "Miles 4\n",
      "Renee 4\n",
      "Charlie 6\n",
      "Hazel 7\n",
      "Eric 9\n",
      "Niya 9\n",
      "Natalie 9\n",
      "RosÃ© 10\n",
      "River 10\n",
      "Flynn 12\n",
      "Cooper 12\n",
      "Addi 13\n",
      "Ellie 15\n",
      "Dorian 15\n",
      "Theo 15\n",
      "Tristen 15\n",
      "Willow 16\n",
      "Ginny 16\n",
      "Bran 17\n",
      "Jon 19\n",
      "Arya 19\n",
      "Nova 21\n",
      "Freya 21\n",
      "Sirius 22\n",
      "Stacey 22\n",
      "Kasey 23\n",
      "Taylor 25\n",
      "Tayler 25\n",
      "Tegan 29\n",
      "Archer 29\n",
      "Blaire 30\n",
      "Brooke 30\n",
      "Brendon 30\n",
      "Hope 30\n",
      "Bella 30\n",
      "Ever 34\n",
      "Jake 34\n",
      "Romeo 35\n",
      "Caesar 35\n",
      "Harry 36\n",
      "Dustin 36\n",
      "LeoJr 37\n",
      "Logan 38\n",
      "Holly 39\n",
      "Hayley 39\n",
      "Olivia 40\n",
      "ChelseaJr 42\n",
      "Annie 42\n",
      "Ashton 42\n",
      "Phoebe 44\n",
      "Owen 46\n",
      "Lucien 46\n",
      "Autumn 47\n",
      "August 47\n",
      "Mars 48\n",
      "Conner 48\n",
      "Blake 50\n",
      "Hannah 52\n",
      "Elliot 52\n",
      "Oliver 55\n",
      "Kelly 56\n",
      "Wesley 56\n",
      "Henry 57\n",
      "Holden 57\n",
      "Josie 61\n",
      "Cove 61\n",
      "Delilah 62\n",
      "Danyel 62\n",
      "Ruth 63\n",
      "Todd 64\n",
      "Jacob 64\n",
      "Eileen 68\n",
      "Waldo 68\n",
      "Jennie 69\n",
      "Rebekah 70\n",
      "Dwayne 70\n",
      "Loki 71\n",
      "Eleanor 71\n",
      "Koya 73\n",
      "Rain 73\n",
      "Baby 74\n",
      "Jane 74\n",
      "Han 76\n",
      "Hwan 76\n",
      "Keira 77\n",
      "Teddy 78\n",
      "Levi 79\n",
      "Belle 79\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{1: {'child': ['Olive'], 'parent': ['Marcus Flex']},\n",
       " 2: {'child': ['Brielle', 'Jaime'],\n",
       "  'parent': ['Dominic Fyres', 'J Huntington III']},\n",
       " 4: {'child': ['Alexis', 'Miles', 'Renee'],\n",
       "  'parent': ['Sergio Romeo', 'Lars Rosewood']},\n",
       " 6: {'child': ['Charlie'], 'parent': ['Craig Slater']},\n",
       " 7: {'child': ['Hazel'], 'parent': ['Kim Mingyu']},\n",
       " 9: {'child': ['Eric', 'Niya', 'Natalie'],\n",
       "  'parent': ['Caron Simmons', 'Steven Smith']},\n",
       " 10: {'child': ['RosÃ©', 'River'], 'parent': ['Maria Wills']},\n",
       " 12: {'child': ['Flynn', 'Cooper'], 'parent': ['Cayden Cross']},\n",
       " 13: {'child': ['Addi'], 'parent': ['Yusuf Malik']},\n",
       " 15: {'child': ['Ellie', 'Dorian', 'Theo', 'Tristen'],\n",
       "  'parent': ['Craig Dream Daddy', 'Hailey Willis']},\n",
       " 16: {'child': ['Willow', 'Ginny'], 'parent': ['Hamza Mounib']},\n",
       " 17: {'child': ['Bran'], 'parent': ['Kade Pelletier']},\n",
       " 19: {'child': ['Jon', 'Arya'], 'parent': ['Korbin Sherwood']},\n",
       " 21: {'child': ['Nova', 'Freya'], 'parent': ['Chance Turner']},\n",
       " 22: {'child': ['Sirius', 'Stacey'], 'parent': ['Jordan Weir']},\n",
       " 23: {'child': ['Kasey'], 'parent': ['Jace Thomas']},\n",
       " 25: {'child': ['Taylor', 'Tayler'], 'parent': ['Khaled Al Fassi']},\n",
       " 29: {'child': ['Tegan', 'Archer'], 'parent': ['Hawea Paoa']},\n",
       " 30: {'child': ['Blaire', 'Brooke', 'Brendon', 'Hope', 'Bella'],\n",
       "  'parent': ['Afu Savea', 'Seiji Tanaka']},\n",
       " 34: {'child': ['Ever', 'Jake'], 'parent': ['Derumk Kealoha']},\n",
       " 35: {'child': ['Romeo', 'Caesar'], 'parent': ['Sai Ramesh']},\n",
       " 36: {'child': ['Harry', 'Dustin'], 'parent': ['Duane Talla']},\n",
       " 37: {'child': ['LeoJr'], 'parent': ['Leonardo DiCaprio']},\n",
       " 38: {'child': ['Logan'], 'parent': ['Serena Moore']},\n",
       " 39: {'child': ['Holly', 'Hayley'], 'parent': ['James Potter']},\n",
       " 40: {'child': ['Olivia'], 'parent': ['Tom Holland']},\n",
       " 42: {'child': ['ChelseaJr', 'Annie', 'Ashton'],\n",
       "  'parent': ['Finnegan Lambert', 'Theo Beckett']},\n",
       " 44: {'child': ['Phoebe'], 'parent': ['Remus Lupin']},\n",
       " 46: {'child': ['Owen', 'Lucien'], 'parent': ['Leonardo Parish']},\n",
       " 47: {'child': ['Autumn', 'August'], 'parent': ['Noel Fritz']},\n",
       " 48: {'child': ['Mars', 'Conner'], 'parent': ['Brooke Pieterson']},\n",
       " 50: {'child': ['Blake'], 'parent': ['Darrel Charm']},\n",
       " 52: {'child': ['Hannah', 'Elliot'], 'parent': ['Fetu Paewai']},\n",
       " 55: {'child': ['Oliver'], 'parent': ['Stephen Andersen']},\n",
       " 56: {'child': ['Kelly', 'Wesley'], 'parent': ['Ryder Milligan']},\n",
       " 57: {'child': ['Henry', 'Holden'], 'parent': ['Adam Beast']},\n",
       " 61: {'child': ['Josie', 'Cove'], 'parent': ['Jase Marroquin']},\n",
       " 62: {'child': ['Delilah', 'Danyel'], 'parent': ['Fred Jenson']},\n",
       " 63: {'child': ['Ruth'], 'parent': ['Messiah Reed']},\n",
       " 64: {'child': ['Todd', 'Jacob'], 'parent': ['Carlos Dias']},\n",
       " 68: {'child': ['Eileen', 'Waldo'], 'parent': ['Aquaman Momoa']},\n",
       " 69: {'child': ['Jennie'], 'parent': ['BTS Namjoon']},\n",
       " 70: {'child': ['Rebekah', 'Dwayne'], 'parent': ['BTS Jungkook']},\n",
       " 71: {'child': ['Loki', 'Eleanor'], 'parent': ['Monica Geller']},\n",
       " 73: {'child': ['Koya', 'Rain'], 'parent': ['BTS Jimin']},\n",
       " 74: {'child': ['Baby', 'Jane'], 'parent': ['BTS J-Hope']},\n",
       " 76: {'child': ['Han', 'Hwan'], 'parent': ['BTS Taehyung']},\n",
       " 77: {'child': ['Keira'], 'parent': ['Ekam Khosa']},\n",
       " 78: {'child': ['Teddy'], 'parent': ['Cataleya Collins']},\n",
       " 79: {'child': ['Levi', 'Belle'], 'parent': ['Maleficent Moors']}}"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "children_parents_episodes = {}\n",
    "for i in range(len(total)):\n",
    "    name = total[i][0]\n",
    "    episode = get_birth_episode(name)\n",
    "    print(name, episode)\n",
    "    if(episode in children_parents_episodes):\n",
    "        children_parents_episodes[episode][\"child\"].append(name)\n",
    "        parent_name = total[i][1]\n",
    "        if(parent_name not in children_parents_episodes[episode][\"parent\"]):\n",
    "            children_parents_episodes[episode][\"parent\"].append(parent_name)\n",
    "    else:\n",
    "        children_parents_episodes[episode] = {\"child\": [name]}\n",
    "        children_parents_episodes[episode][\"parent\"] = [total[i][1]]\n",
    "\n",
    "write_json(children_parents_episodes, data_path.joinpath(\"children_parents_per_episode.json\"))\n",
    "children_parents_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}